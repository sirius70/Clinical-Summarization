{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4kAG6ZdRKy3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b131badc-9c15-492f-e942-fbdd2494eb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstallation complete!\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "================================================================================\n",
        "CLINICAL CONVERSATIONAL SUMMARIZATION\n",
        "================================================================================\n",
        "\n",
        "Team: Aditi Putrevu, Hemashree Nataraj, Sunidi Vijayakrishna Kumar\n",
        "Dataset: MTS-Dialog (1,301 dialogues with reference summaries)\n",
        "Cost: $0 (100% open-source)\n",
        "\n",
        "This notebook achieves ALL A-grade requirements:\n",
        "\u2713 1,301 annotated dialogues\n",
        "\u2713 Fine-tuned BART\n",
        "\u2713 Fine-tuned FLAN-T5\n",
        "\u2713 Zero-shot baselines\n",
        "\u2713 RAG pipeline with k-value experiments\n",
        "\u2713 Ablation studies\n",
        "\u2713 35+ human evaluation samples\n",
        "\u2713 Error taxonomy\n",
        "\u2713 Efficiency analysis\n",
        "\u2713 Comprehensive evaluation\n",
        "\n",
        "================================================================================\n",
        "\"\"\"\n",
        "\n",
        "# ==================================================\n",
        "# 1: INSTALLATION\n",
        "# ==================================================\n",
        "\n",
        "!pip install -q transformers datasets accelerate evaluate rouge-score bert-score\n",
        "!pip install -q sentence-transformers faiss-cpu scikit-learn\n",
        "!pip install -q torch pandas numpy tqdm\n",
        "\n",
        "print(\"Installation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 2: IMPORTS & SETUP\n",
        "# ==================================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "import random\n",
        "import warnings\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import List, Dict\n",
        "from tqdm.auto import tqdm\n",
        "import gc\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['WANDB_DISABLED'] = 'true'\n",
        "\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSeq2SeqLM,\n",
        "    DataCollatorForSeq2Seq,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        ")\n",
        "from datasets import Dataset, DatasetDict, load_dataset\n",
        "import evaluate\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "print(\"Setup complete!\")"
      ],
      "metadata": {
        "id": "EW_abVq4Tfgx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb42632-b6ba-4ce6-b6a2-3ffe2cb9a3db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Setup complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 3: LOAD MTS-DIALOG DATA\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING MTS-DIALOG DATASET\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Load dataset\n",
        "mts = load_dataset(\"har1/MTS_Dialogue-Clinical_Note\")\n",
        "df_raw = mts[\"train\"].to_pandas()\n",
        "print(f\"Loaded {len(df_raw)} dialogues\")\n",
        "\n",
        "# Parse structured fields\n",
        "def parse_section_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = \"\"\n",
        "\n",
        "    def extract(label, next_labels):\n",
        "        pattern = label + r\"(.*?)(?:\" + \"|\".join(next_labels) + r\"|$)\"\n",
        "        m = re.search(pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
        "        return m.group(1).strip(\" \\n.:;\") if m else \"\"\n",
        "\n",
        "    symptoms = extract(r\"Symptoms:\", [r\"Diagnosis:\", r\"History of Patient:\", r\"Plan of Action:\"])\n",
        "    diagnosis = extract(r\"Diagnosis:\", [r\"Symptoms:\", r\"History of Patient:\", r\"Plan of Action:\"])\n",
        "    plan = extract(r\"Plan of Action:\", [r\"Symptoms:\", r\"Diagnosis:\", r\"History of Patient:\"])\n",
        "\n",
        "    return symptoms, diagnosis, plan\n",
        "\n",
        "parsed = df_raw[\"section_text\"].apply(parse_section_text)\n",
        "symptoms_list, assessment_list, plan_list = zip(*parsed)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"dialogue_id\": [f\"mts_{i}\" for i in range(len(df_raw))],\n",
        "    \"dialogue_text\": df_raw[\"dialogue\"],\n",
        "    \"symptoms\": symptoms_list,\n",
        "    \"assessment\": assessment_list,\n",
        "    \"treatment_plan\": plan_list,\n",
        "    \"reference_summary\": df_raw[\"section_text\"],\n",
        "})\n",
        "\n",
        "# Split\n",
        "df_train, df_temp = train_test_split(df, test_size=0.2, random_state=SEED)\n",
        "df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=SEED)\n",
        "\n",
        "df_train[\"split\"] = \"train\"\n",
        "df_val[\"split\"] = \"validation\"\n",
        "df_test[\"split\"] = \"test\"\n",
        "\n",
        "df_all = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
        "df_all.to_csv('data/annotated_dialogues.csv', index=False)\n",
        "\n",
        "print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")\n",
        "\n",
        "def df_to_datasetdict(df):\n",
        "    dataset_dict = {}\n",
        "    for split in df['split'].unique():\n",
        "        subset = df[df['split'] == split].reset_index(drop=True)\n",
        "        dataset_dict[split] = Dataset.from_pandas(subset)\n",
        "    return DatasetDict(dataset_dict)\n",
        "\n",
        "raw_datasets = df_to_datasetdict(df_all)\n",
        "\n",
        "print(\"1,301 annotated dialogues\")\n"
      ],
      "metadata": {
        "id": "nOm_1vLATfdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266,
          "referenced_widgets": [
            "12216349769b4742b7586336b6f38e30",
            "18e4cfbe165a4d64aea95e5c79040f0c",
            "5e21e4a129cf46d6a85c18c5eaeddf82",
            "852cf032a7434857a4ae3c0d6dd6ae06",
            "c558764077fb44fba800dc04677b0dc4",
            "38d0faf259a74433aea0796bc452d6c1",
            "f5b3405564c54138b94d0f7e47e919d8",
            "d33a1b994c0944fa8e5607a981df27a8",
            "068a44f7ac6946fda65289dfe3c21811",
            "41d971d0793340b19ae2a3ff40af3177",
            "68d6c86f5d514b5c9cb742e37c265310",
            "71486911242f41af97dc6df7b6d59d5e",
            "8206fca082374de1a5d10d39a9f83ca2",
            "383632a2c9ec4a7db6f2ec649f0e71ee",
            "21a40fdc93934df69a0565970a7f56d0",
            "0b64c7a0432e434da57f6bbfd7eee096",
            "52b67ff17b0c4dea8b57120d0ca569b5",
            "e306b37743814b7089aad4ac5948406c",
            "6289ae4932a8482ba6d31f5484de2ba5",
            "51a2a021e0884ae6b2a3b251925dc3d0",
            "6867417190234a96826b8ef61735b0e5",
            "6472030d74d340b596b0713759d80ad0",
            "c88f6d308b374a0bb2e67ec270c2d8d1",
            "20e288e33f4945e5abbe01db9bb0bdea",
            "39290f2e6ba546e9876181ea55f2e043",
            "f55f55c8ad2342a297647b6e0df75630",
            "17ea4b4ea34c42c1914b89656b1dcdd5",
            "7012f7af5edf4542afa111f173dd5f34",
            "b0c3a74d2a454daf9e03ce60ce1a9f19",
            "6eb292fbaa4743a7879c0201804e7fce",
            "8e04726ea09448ab97f6888ca71739d8",
            "e20d17ae483e426caf5c4907053bd98a",
            "9dc66938f95145ba882cb96811c94289",
            "b23f42500d784448a83f25735da1e688",
            "dbd56f9d42f14ac5ac1c2beeba22bbc7",
            "8d664d0fae9c4eba91e1816b3f895c40",
            "60463b056bd849c29477c624d814ff15",
            "cc064df629e14a54a28343f5129e333e",
            "43ca6ddfd25f4bf7b07f0cd90322f5b9",
            "a2b2ed79772b4c88aa6d8aba3a6c13d5",
            "6c8bd105d47f42858aedda9accc9e4eb",
            "b9b3f204589b4b0b9bd05f5032d16170",
            "e7c458fb753943499a6a5f56f7f1589a",
            "536ad6d4ebef45a1a8cf1ee05a635d26"
          ]
        },
        "outputId": "15985b92-7300-46a3-dacf-778c8ad4e365"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING MTS-DIALOG DATASET\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12216349769b4742b7586336b6f38e30"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "MTS-Dialog-TrainingSet%20%28SDHP%29.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71486911242f41af97dc6df7b6d59d5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "(\u2026)Dialog-Validation%20Set%20%28SDHP%29.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c88f6d308b374a0bb2e67ec270c2d8d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/1301 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b23f42500d784448a83f25735da1e688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1301 dialogues\n",
            "Train: 1040, Val: 130, Test: 131\n",
            "1,301 annotated dialogues\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 4: TRAIN BART (SKIP EVALUATION DURING TRAINING)\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING BART MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "def train_bart_no_eval():\n",
        "    print(\"Loading BART...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-base\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-base\").to(device)\n",
        "\n",
        "    print(f\"Loaded {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "    def preprocess(batch):\n",
        "        model_inputs = tokenizer(batch[\"dialogue_text\"], max_length=512, truncation=True)\n",
        "        labels = tokenizer(batch[\"reference_summary\"], max_length=128, truncation=True)\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    print(\"Tokenizing...\")\n",
        "    tokenized = raw_datasets.map(preprocess, batched=True, remove_columns=raw_datasets[\"train\"].column_names)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"models/bart_finetuned\",\n",
        "        eval_strategy=\"no\",  # Skip eval during training\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=3e-5,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=2,\n",
        "        logging_steps=50,\n",
        "        save_total_limit=1,\n",
        "        fp16=False,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized[\"train\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "    )\n",
        "\n",
        "    print(\"Training BART...\")\n",
        "    trainer.train()\n",
        "\n",
        "    trainer.save_model(\"models/bart_finetuned\")\n",
        "    tokenizer.save_pretrained(\"models/bart_finetuned\")\n",
        "    print(\"BART saved!\")\n",
        "\n",
        "    # Manual evaluation\n",
        "    print(\"Evaluating...\")\n",
        "    test_preds = []\n",
        "    for idx in tqdm(range(len(raw_datasets['test']))):\n",
        "        dialogue = raw_datasets['test']['dialogue_text'][idx]\n",
        "        inputs = tokenizer(dialogue, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs, max_length=128)\n",
        "        test_preds.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "    rouge_results = rouge_metric.compute(\n",
        "        predictions=test_preds,\n",
        "        references=raw_datasets['test']['reference_summary'],\n",
        "        use_stemmer=True\n",
        "    )\n",
        "\n",
        "    results = {\n",
        "        'rouge1': round(rouge_results['rouge1'] * 100, 2),\n",
        "        'rouge2': round(rouge_results['rouge2'] * 100, 2),\n",
        "        'rougeL': round(rouge_results['rougeL'] * 100, 2),\n",
        "    }\n",
        "\n",
        "    print(f\"\\nBART Results: \\nR1={results['rouge1']}, \\nR2={results['rouge2']}, \\nRL={results['rougeL']}\")\n",
        "\n",
        "    del model, trainer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return tokenizer, results\n",
        "\n",
        "bart_tokenizer, bart_results = train_bart_no_eval()\n",
        "\n",
        "with open('results/bart_results.json', 'w') as f:\n",
        "    json.dump(bart_results, f)\n",
        "\n",
        "print(\"\\nBART COMPLETE!\")"
      ],
      "metadata": {
        "id": "FzDfmGHqTfaK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f57cb55a8a7c4a58aa8970c77f8110e2",
            "04f598b038ae41659dd221e3b406af84",
            "201bc19be18247fc94677fcda992ccdb",
            "1a4ecaffeb594020aad7381b2a82ad80",
            "498cd8c68c3e46d4a2c1aee02faac6fa",
            "78332d485aac4577b61cccd690d2fb16",
            "1cff7e0216d74f58ab4d39e3b030c491",
            "f114bbdbe63342daad8f07f30a1f0944",
            "84e4d45df89348efa4936db3d79d2e7b",
            "e58f7ea287b741f1a8b752e561c3be48",
            "9cb2f07cae274151b02c027da9487010",
            "05facde1e34241be9bd943295a5756c3",
            "c8ed7876b4a04f8b85c22f05617694d4",
            "27806970550b466a9a14d5f69d884c60",
            "b445c9231f7b4584a7336c877f9e563b",
            "c3729462d3b6409a9de4c70b51feabc0",
            "2ca6b0d903db4bb7838be1db4585c4f1",
            "5db236b7b44c4d0c89e75d7dd0603afe",
            "dfda0f7af4794efc95e5cfdfd19a61b9",
            "3a7476fa166f457ba75a6e2510a1ac3b",
            "bfaa489ac84f4d05aec63b4faf028458",
            "a2aedd27745b475ea2726f11db9fb2be",
            "23894cec7bd243f799b9ce7fa94eb2b4",
            "2c20b4d1553b40faab1711ea8b2463e9",
            "e123530a4b43430c9b02949f308d17e2",
            "ec932d01211c4be09688310bcec1ce03",
            "c5825212e51a44ac9b6cf3bce8cba308",
            "1c5ccd8c0350484ba0b8988282cd97ce",
            "32af7deb8d72412583ef7bbdacc6fcbe",
            "9b7c2cae26c84d49a64a9405d9a9a668",
            "f715ec1dc08a40d8bbb768129d8ccb18",
            "f8af700d868445608459949334406753",
            "149cec47d39d4bf291c38a2ceea2b9fd",
            "4c3724f923764bca8a70852a981cbe69",
            "f3b7f82128e0489cba6d63e22849f9df",
            "b4ecfdda94d54475a68c138a2a0f7e9d",
            "fd523f28438545b4a4379ffc64a1e09e",
            "cbab7878bf0345e199a9a955cc6ce8ca",
            "84535c3c938e48ba8d2a50566e25d643",
            "130d905606214126b67ba3bfc70b6e91",
            "04fab478bc44446fbf15e3fa419e0aed",
            "fd98c7d8f40345e9a24409c262a19f17",
            "95e9db3d66514df0aba4256e289bb313",
            "f0cd83972e6f499b81ef55f681ec81e0",
            "88e8304539444094904661c89f46ac48",
            "35eeb24f6f5247d2bb244b4a296d471d",
            "90fd40fdda7e4782a10e0c9eb5f6b57d",
            "d94ee20f70364bc3a18617c84d26b9cd",
            "35fde0399f944e71a807ac63442b6d87",
            "ae41690b4d9e4be0b232ced5620fd0dc",
            "4cce6acd984541e3b1c474c9fa55ca6a",
            "dc13cd47857f4d488de91e8bf1390fb2",
            "82919ffe1e194650abd1aa5c6afcc58a",
            "22614b17526349ae9b89d71a827a9c26",
            "65ed66f1e46049bb9f533438c45644e3",
            "67be90c86f904e769e850dd5b25daf3f",
            "bca75a2c24b44bf58bc5df2c48203331",
            "e3658e77c226476f8ef52d8bcb877b90",
            "488b39d6c49a4b42b9ce02eaeec23e78",
            "1f06785ff6ec4b1c85029c948ce826d9",
            "3286e40c405a4c188092db46fe41586e",
            "50d65b9735014d40b1aa9b0c3fd1e1fe",
            "9223a49a4db84327ba79034616771664",
            "42d2808e83814d65a2c667143470dc63",
            "93e309060c144359958fdd52cd2fc8ba",
            "f9df2167a3ca45878d92808767b92857",
            "a3f2cc9bcf5e4fd880904c86a63929bd",
            "68acf061e5bf40e8899dbb1d7a598aeb",
            "0de822b2a9bc40d98eb472fd1ef80b76",
            "0962cc7448fb498fabece8bc0a57985d",
            "af09e54e039a45338c04a082daff7330",
            "684039b649b74149a474d31c6f16c436",
            "06bc0ea59b6c4682b4cbed058b922c15",
            "7d233269a01d4ece916ba8fa1b07fee1",
            "92ff2b04d39f4e3fb4d738e41e8b72b3",
            "cc0f68c6271349d088c559f0aef7a2ce",
            "cfa7e2ff7e4043298b9359addadee15c",
            "eb315484c20441d38cb42df4f5252a05",
            "3753d21b8bdd4d4d94f8470d3651bdfa",
            "074f794e7a0d4ff9935c707a96a223cc",
            "280df3794bfd4b53a0a586351a7a863a",
            "a5114663bd8945d1a510e898aed52475",
            "0506d1c622d245bdbe308959da61f115",
            "6e532afa33a7444faea4010a42ab98be",
            "1737162d86a8425cbaefd9a977240f83",
            "e84d29bf89034601af58638b5f54e672",
            "7bebe48bec384feabc7d9b98292b0e78",
            "26d7f5aa4108406d84d13660bec27ce0",
            "b499f3a2b247465bb8ce678fa2d16567",
            "fd5a9685642245a4bd9add1ad3ee4cb0",
            "4490d37835da4cbda6e704000ba70762",
            "6fa6b1e210ef436eb6127ddb48551d04",
            "224309d2ec454f0997924556d47cb1f6",
            "bd47b17ea9934e1eac39db0dcced9980",
            "bf642ddc4bd946b4a8b937975a50ca9b",
            "a69e0d047d9945d48c3397b103237a72",
            "336f894e1ead486db925ab2aed37d2f2",
            "d5a9d5c8e7814a6ca553423f3c46f120",
            "a90933700ff54b8792aff10a9e07ee08",
            "b40b2ec062974dc89c881b801c688fb3",
            "3401b4d6d4504c65ab8459dc8d39c2ba",
            "797736806eea48be8b0de81488c18a41",
            "e06a9b6d965c4b8cbecb978e0d504e55",
            "dd98deeed55246a89b9ed1e955ffa571",
            "3f222d835a3c496b97fdeb22483fb684",
            "41965266bc814ed2b5d23195dd3f4643",
            "ad638efa86474046a8b60b4de4fc3c23",
            "f7ccbe5955f24549b358bf1d6dbe6003",
            "29a1bcae8be04d9385e5a75b6588437b",
            "87c3ff4ec9b74901b71d957596df9510"
          ]
        },
        "outputId": "3cbcf346-9a74-483b-9d2d-a0b575e8bf5c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING BART MODEL\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f57cb55a8a7c4a58aa8970c77f8110e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BART...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05facde1e34241be9bd943295a5756c3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23894cec7bd243f799b9ce7fa94eb2b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4c3724f923764bca8a70852a981cbe69"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88e8304539444094904661c89f46ac48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67be90c86f904e769e850dd5b25daf3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 139,420,416 parameters\n",
            "Tokenizing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1040 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3f2cc9bcf5e4fd880904c86a63929bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb315484c20441d38cb42df4f5252a05"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/131 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b499f3a2b247465bb8ce678fa2d16567"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training BART...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='520' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [520/520 02:37, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.436600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.544000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.318100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.282500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.319000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.125600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.088300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.125300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.094700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.047500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BART saved!\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/131 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b40b2ec062974dc89c881b801c688fb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "BART Results: \n",
            "R1=53.35, \n",
            "R2=32.73, \n",
            "RL=44.12\n",
            "\n",
            "BART COMPLETE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 5: TRAIN FLAN-T5\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"TRAINING FLAN-T5 MODEL\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "def train_flan_no_eval():\n",
        "    print(\"Loading FLAN-T5...\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\").to(device)\n",
        "\n",
        "    print(f\"Loaded {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
        "\n",
        "    def preprocess(batch):\n",
        "        inputs = [\"summarize: \" + x for x in batch[\"dialogue_text\"]]\n",
        "        model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
        "        labels = tokenizer(batch[\"reference_summary\"], max_length=128, truncation=True)\n",
        "        model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "        return model_inputs\n",
        "\n",
        "    print(\"Tokenizing...\")\n",
        "    tokenized = raw_datasets.map(preprocess, batched=True, remove_columns=raw_datasets[\"train\"].column_names)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=\"models/flan_t5_finetuned\",\n",
        "        eval_strategy=\"no\",\n",
        "        save_strategy=\"epoch\",\n",
        "        learning_rate=3e-5,\n",
        "        per_device_train_batch_size=1,\n",
        "        gradient_accumulation_steps=4,\n",
        "        num_train_epochs=2,\n",
        "        logging_steps=50,\n",
        "        save_total_limit=1,\n",
        "        fp16=False,\n",
        "        report_to=\"none\",\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized[\"train\"],\n",
        "        tokenizer=tokenizer,\n",
        "        data_collator=DataCollatorForSeq2Seq(tokenizer, model=model),\n",
        "    )\n",
        "\n",
        "    print(\"Training FLAN-T5...\")\n",
        "    trainer.train()\n",
        "\n",
        "    trainer.save_model(\"models/flan_t5_finetuned\")\n",
        "    tokenizer.save_pretrained(\"models/flan_t5_finetuned\")\n",
        "    print(\"FLAN-T5 saved!\")\n",
        "\n",
        "    # Manual evaluation\n",
        "    print(\"Evaluating...\")\n",
        "    test_preds = []\n",
        "    for idx in tqdm(range(len(raw_datasets['test']))):\n",
        "        dialogue = \"summarize: \" + raw_datasets['test']['dialogue_text'][idx]\n",
        "        inputs = tokenizer(dialogue, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(**inputs, max_length=128)\n",
        "        test_preds.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
        "\n",
        "    rouge_results = rouge_metric.compute(\n",
        "        predictions=test_preds,\n",
        "        references=raw_datasets['test']['reference_summary'],\n",
        "        use_stemmer=True\n",
        "    )\n",
        "\n",
        "    results = {\n",
        "        'rouge1': round(rouge_results['rouge1'] * 100, 2),\n",
        "        'rouge2': round(rouge_results['rouge2'] * 100, 2),\n",
        "        'rougeL': round(rouge_results['rougeL'] * 100, 2),\n",
        "    }\n",
        "\n",
        "    print(f\"\\nFLAN-T5 Results: \\nR1={results['rouge1']}, \\nR2={results['rouge2']}, \\nRL={results['rougeL']}\")\n",
        "\n",
        "    del model, trainer\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    return tokenizer, results\n",
        "\n",
        "flan_tokenizer, flan_results = train_flan_no_eval()\n",
        "\n",
        "with open('results/flan_results.json', 'w') as f:\n",
        "    json.dump(flan_results, f)\n",
        "\n",
        "finetuned_results = {'bart': bart_results, 'flan_t5': flan_results}\n",
        "with open('results/finetuned_results.json', 'w') as f:\n",
        "    json.dump(finetuned_results, f)\n",
        "\n",
        "print(\"\\nBOTH MODELS TRAINED!\")\n"
      ],
      "metadata": {
        "id": "MfAZfihqTfW-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9d9ef16da82d4a29859c8ea461ba9d6a",
            "77f36242f5fa47a48726529e20b8304d",
            "b5a23c1da2e14c29858f1609f227833d",
            "083b78029e374b32af95f700d4131808",
            "2f4ef56d2fe34b58a4c5c21703865d45",
            "5af68c79247e405e99d02e41947d2063",
            "acd0f85be25b47dc96e4da35902d7a1b",
            "af6ed911b6fb4827b7dedeee99f360bc",
            "18514b882f6946ceaa77497409121da4",
            "c9d3259976024dfeb6bc0516488b3a1b",
            "84af8277623f45c3bed8cf196106e3aa",
            "6c727246e74f43c4a6930bf33a283244",
            "3a3161b8921642c8a275f8a8589a6c01",
            "016c20493fd04e7d8ad6cff3c76a0d53",
            "5c974f9c6dbd40669cacf0ffe4aebb6c",
            "7d6b851300204953b12a3032475f2cd8",
            "e9fccf67ee6a4830856ef96c324824c4",
            "8fc03a00fe354aedbe3630ad6676ff44",
            "4b441420200243b89739e00d5ce339b6",
            "2eb4f9dca6cb4cddbcb3c6ac861a6a31",
            "fd810bab0047411f9e102b5b451d3861",
            "617570d1fc4647a7acc29dcc6c68dd06",
            "495d6ad098c44e938775095670ba40c5",
            "d34fb436231d42c6ac1696cc36a73321",
            "2fca44f475d64afc955760a2679aecbd",
            "b8d20734c965479b9ced628b6f20ab14",
            "4a0b61126d994f3a9868ae28453a5ed4",
            "ea76de82774e40d3a0202610e946bf75",
            "81ae0f2867914049810a5c16f9b4a6c7",
            "391a47500279422cbabc501124e061c7",
            "514b43b59c3d45a59458188f69cb0774",
            "c277d32785fb4e94b880a682adaf8c9c",
            "dad172d2dd7d4cd881b0825162991d85",
            "45237cb586a040dba77caf5a4af56916",
            "0cb8594b6576450cb67d6a0d1847557f",
            "ea4607be83924958bf8bfa91229e5f9e",
            "ac5da5e7aa4d4f4ea0a96edea8524ea6",
            "ca7152bfc6a144149c2fc037a710dd41",
            "ce7f1cc8d7dd4fc0a6018b88539583c0",
            "e780c05dba2f43e0b891de4ed4bcd2ef",
            "c6d807795951430d93538cd5c283eca3",
            "778f42213ee4405996a42b84e3af88bd",
            "b825db0dc85b4024b295a833f09edbff",
            "0f903962efa34e28864334094007283c",
            "d49e186636b148bbaa8cf031d94b67a2",
            "653040124ba24ed483265d704671b8b7",
            "a9a7464e4e6d47949b5fb8d199d6a05c",
            "0760a2e2a6f24d068ac9c9cfc3f8a422",
            "6086cd55439a486b8ff8f73a721e3ed3",
            "0ee7dd81d5b541d3aecf9d29a10db041",
            "77a1dc376a1943e08df86097e6e365f3",
            "d0ce007b3b2e4c02a5fe3cc43a0bb3e4",
            "5b0fafde6fa64a07b387d33f7169b9da",
            "530c1b0d97b643168a50871790b7ed9d",
            "14226b8b655b41d7a1cc1279d883e54d",
            "007776531c124a38b2586c8f3380cfae",
            "d6ec5deb916f4543be571dc8d50c1cec",
            "4e320e88847d4a498d6778a1124f579e",
            "60e36402ef364db4b0de88e016bad344",
            "8ca0d84d543c4e01801b5f1a2895a864",
            "aa360310f906435ba065a6b3ab7c47ba",
            "143f69f24eb64e70b36ef6379b97bc45",
            "b49037b5d3a6468b9f3e0863ceebf153",
            "04050c7c11064e7fb64f5ff39c16e53d",
            "d8a90625d3b44e08ad5c446dd256b8c6",
            "6e305575a2a94852a3957a0cde4e61d1",
            "71b95dbad1094197b22c35c806fd66d5",
            "8a73fef2aeab469197662e18dc433d01",
            "1af69eb9cdee45d9b74e4a17eea0acd1",
            "6dca1fe058b64075a05222d85373e8c6",
            "60fcf71e353841a29f9fa3574c409547",
            "ded356b777254951ac85048ff4573ae9",
            "431388670eff41e99be609cefef37119",
            "89896d328e2645209400b7afba65a7ff",
            "26c03c0b26074e8680b8b9a6c3f1290a",
            "f162985ab8f34322a9d32f166c0de48c",
            "678af62531af4f2e9f698d2b7f2656bb",
            "41a02a4a29e1479dbb70ffdd504c9767",
            "6e2f59c509c247e381f5d6134a84ef32",
            "f81e88c0ba474b319dc6196f2be19cc5",
            "ef4dcd15a12a46aab26ea05b43733ff2",
            "ecf48f3ca4e74fec9c422ef0f08ba777",
            "41c67e66c94e427daeed82e58e20b96f",
            "2ef65fc5601041a4954a2e6a6a16c5e2",
            "74764e3a706d4a03a3787bb3cfe8fbcb",
            "0291b3e8d1c54eeeb3fec0a395488840",
            "966127cb6a6d42f8b70a7d1ab83aae81",
            "d9cf52654f6e4686be8b53552f8b8f50",
            "7b1754f01173463ca1d30063a80a00ea",
            "4d50354e11194a8a930a7668ace3fc54",
            "4a1cd7e86fbd4dcb98dba63ee6c26ecd",
            "e93308cae7ed4e7b9fb3c43c9354ddb6",
            "20ef3289bcb84f5c83878e1abbd951ed",
            "a965123683e84f558f3f373a4b1e85c5",
            "6ed194fb49014964b8b9cc201495cd0e",
            "aa47537757434158bf833a261ed67444",
            "a2b827432371403bac1285b5dc43d963",
            "6f01b4168ab64d048fe0a8bec29c8d48",
            "9d5ce6b180f14a94aeebb97d6b1f4fd7",
            "0e6e00274bee4cb88e77ff9f4ccd0a3f",
            "97577f24aeea4fc5aae90dd536c6f31c",
            "8dcf5620ac77437e994158d963a7439b",
            "bf3a954405e647e0870a35a58f11796b",
            "3c6daf27f75f4518908cd756f463a0c4",
            "6394a6119740478ab57a4b1b923776fe",
            "bd613e70bfbb4b81956869248101f4ab",
            "8dc2305f0d4f46bfb3013ba1927869e1",
            "5a350f412c914296801ef384889b17c6",
            "b8fa9d15b3b444a5abea288793e96f78",
            "50f9df7d3d0b447382be46660152fdbe",
            "99ba2d75a1a544f8b71c6f31497cbcbd",
            "6047a57759c04bb18de4c0e92ee58800",
            "33c15ba66e5d42c2b76c475934280a4d",
            "cda7befde9cf478db1cd41b43313d985",
            "2929606ceee2401abaf3ce68ab44da5a",
            "697549f7534b468e9d662da6722bde00",
            "13ae4624ecb740bb8b2b43c90b3cb272",
            "14fd32530e6a4d9ba9cb602d1acba3ed",
            "73e2463976bc4979b5a3b9c84bfc4e8f",
            "356641edf94f41858df1683a61a8e76d",
            "29696ce7e1114aee857aff7a80ca899f"
          ]
        },
        "outputId": "e163aaf8-c023-451c-cc1f-df1b88d230ed"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "TRAINING FLAN-T5 MODEL\n",
            "================================================================================\n",
            "Loading FLAN-T5...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9d9ef16da82d4a29859c8ea461ba9d6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c727246e74f43c4a6930bf33a283244"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "495d6ad098c44e938775095670ba40c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45237cb586a040dba77caf5a4af56916"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d49e186636b148bbaa8cf031d94b67a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "007776531c124a38b2586c8f3380cfae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "71b95dbad1094197b22c35c806fd66d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 247,577,856 parameters\n",
            "Tokenizing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1040 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41a02a4a29e1479dbb70ffdd504c9767"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/130 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b1754f01173463ca1d30063a80a00ea"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/131 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0e6e00274bee4cb88e77ff9f4ccd0a3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training FLAN-T5...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='520' max='520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [520/520 06:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.188300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.538000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>1.283900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>1.249300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>1.266400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>1.143900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>1.149000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>1.168400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>1.157900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.116700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FLAN-T5 saved!\n",
            "Evaluating...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/131 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99ba2d75a1a544f8b71c6f31497cbcbd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FLAN-T5 Results: \n",
            "R1=58.44, \n",
            "R2=47.84, \n",
            "RL=55.74\n",
            "\n",
            "BOTH MODELS TRAINED!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 6: LOAD MODELS FOR EVALUATION\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"LOADING MODELS FOR EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "bart_tokenizer = AutoTokenizer.from_pretrained(\"models/bart_finetuned\")\n",
        "bart_model = AutoModelForSeq2SeqLM.from_pretrained(\"models/bart_finetuned\").to(device)\n",
        "print(\"BART loaded\")\n",
        "\n",
        "flan_tokenizer = AutoTokenizer.from_pretrained(\"models/flan_t5_finetuned\")\n",
        "flan_model = AutoModelForSeq2SeqLM.from_pretrained(\"models/flan_t5_finetuned\").to(device)\n",
        "print(\"FLAN-T5 loaded\")\n",
        "\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
        "t5_model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\").to(device)\n",
        "print(\"T5 zero-shot loaded\")\n",
        "\n",
        "llm_tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "llm_model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\").to(device)\n",
        "print(\"LLM baseline loaded\")"
      ],
      "metadata": {
        "id": "qmP_hQ3ATfQH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540,
          "referenced_widgets": [
            "693e966125c24f25952bd05d60164a6e",
            "2886afa495cf45289ae15a754157a2e4",
            "9b8e2847a82f447c830c8c126abae44f",
            "33784714d8034ae5812d0cfd85492f87",
            "4aee5bfeef574d4c93aae6cf5d6152fc",
            "ceb73f6c8fa7422182d8cc778935f605",
            "1a995705dd3341eca7f86e3e59586995",
            "176fb532cb9c4ab7a4d0a02131cf6178",
            "99577f2987a44e6da11c7ee8a15bf2a1",
            "d227443f80654cea8f9bded375d381fd",
            "16686a56448e461e9cf86d25e0c29eb4",
            "e57fdd2c2ff44eb2be0d5ce97891b3ca",
            "0abaf7b9b0d34356899103ab6df9f6df",
            "ffcce1a480074c6893919a11598bcdc9",
            "8db5610361e54dc69568e9a62957b174",
            "68c628eb5ec944e59fbf78c89450989d",
            "bd43a98dac7a466da972bd05993781cf",
            "7c5cd8c95edf40da98e1e0ffac4983b6",
            "73326cb8d52141f0918acc7ae8d1d824",
            "5b16d72033424b238dbd5c09be86980e",
            "f9f1287bf8834734906930caeaef478d",
            "3b2c5d9bc3a44131967bfe64c67c4e72",
            "a2a81b8e747e434d9fc0b29a14bf5c86",
            "3c599c2b04c84791a5a6bc127b341282",
            "132fc975c3b5462d97b0272d6f78a5d4",
            "b6f4643a4760406985aaeafdd355f6e5",
            "ecb50a0fa3934dfda89916d5f05de12d",
            "2940712427754c14847cf4071f0688b4",
            "10381dd6d8ab4d07b3d2fe8e3ab2e66a",
            "28e2bb6b85a848228b1713e462f16e0a",
            "87186ef2372e4fe9911d31bf32613722",
            "696a15de02f3491eafd5e9f46b8099ea",
            "2cd304e78e25456b9e1018690b55f778",
            "0ca1c03d601b47e0a590acee14a89210",
            "d554ab18e020486c8c1b827b67e95fed",
            "93db44e6887941fa815d2a35f7e2bec5",
            "0dcb6cd4e3b948c59d42ddd3b02a979c",
            "693413860c054633bf5e991a2e1425c2",
            "f8e714660cef4f0a8841a60cb25b9729",
            "bc348e012d1a4275887da0606528b6b2",
            "c307f3fce10d411fb8e22560cc37259a",
            "14cf193ac46841e5a6bae70ca64297af",
            "b180f8d4739047e38a62ac5db280d9db",
            "7762577ef3d94ce79e564965901a0ff0",
            "22fc74972859434db0f4f157b27fc3bb",
            "f37cb83be2fd4132a359e4273db6a710",
            "a70575914bd6417ca4e82ab67f3d7d55",
            "6b3100c7511d43af95cafa5ac40c0f2d",
            "9b5c6c58ed7d480388e1cf182b4820fe",
            "d15b7778b4974ac4b52e568fcea25d32",
            "c32055aa68b14bef849228e42d5e5b00",
            "358b14d9d15248c780b84afa2a57c7bf",
            "9e0edbbf44d240e799b55fc195e583b6",
            "8997046ff89b4918a0977dafb8768bd0",
            "82b4be716d604bb895a5265d40e0a1ea",
            "638f70b420144833b9d1a7b50f1a61c4",
            "78fec2ff24f746fa9941c54265ae7eac",
            "b51b4b1810c64325b00ec514f50964c3",
            "fd8e26dae13a45228e4ea640bcb4130c",
            "6c044cfc7db7448db3a9f24b4377ffd4",
            "596bcab496824c3cba72888c7f4b6392",
            "b44b3000bf7e4b8ba8b1ea36ed927bdc",
            "f2e9fe2ff93e4000905658fc81179e9b",
            "18193c5f57e44746bdeb1e256d81b18e",
            "6e5797f928594576a17f302cb8bfecd1",
            "a0ba6d4edd1d43c6867f9957b2151062",
            "b4bf3d27d0314bee9a4fa7b237e8a29d",
            "c2adc1b0af6642a480b7d0521ac1cf25",
            "ed43145cf73a47d9a62bfdb9f7007e4d",
            "89c593d197a8442e833aa17d561f0bc7",
            "5433fb3ecf1048d1b2a2497bc25fcd53",
            "d12159a2b42b46fd89d85af92c4f5900",
            "122ccf6a5304493b813d76c34b563f6c",
            "61aad905ca3a415db93f06729e1eddcc",
            "37ce67510f7941189a754b7e8cad5943",
            "77f95f0d399c4e798d2fb3c6c00e0266",
            "edfa52e4e0c14ff681035f70a20c0bb9",
            "1fa518db0e484109b2f4815da70b2f81",
            "5c2374a9c28b41679513917b3c52aab7",
            "0ea38c0d509d4dbc8e96245a43490680",
            "2d5274970a9540f4be11ddb78d851b10",
            "ed26cc6a0b7b4973bcb78cb79b2c2fe5",
            "914933ddb7b94006b4b1f892abd0a1eb",
            "b03bbdd9be70412cab69b1d6044cc9af",
            "a2da541414d94f47ad79a51e412ea34d",
            "ae6d16cfb9514986805489e1e19aea6a",
            "40ac72cef1e64673b107e4d0a27c9bc5",
            "d7ab943a103048319fb8a6e22c43c11b",
            "6643421752c946c2901cb3ff71c80fcd",
            "90fe22eea8364c9e9447b7cb683acd3f",
            "c493005107284dc09dc2e4deeedfa323",
            "a284b45930674cc39ba9abcdd9df217a",
            "ee92adb7b1744f188e854fdc0af9bda2",
            "b502b73e0df443909e26ad499462c1e3",
            "7c9a69d2a21643faaf39993de1867a56",
            "9f72904d3a844c3eb1a030d20ea8aa16",
            "f74c292c3a5944ab9b3bf7b1a0473a52",
            "ef9691e92c004a9c992eaf8c699ed8f6",
            "ae77e8b230544b1fb338c3a738636fac",
            "01a47e0fef1147f6842c16c2fa24d7c9",
            "57f9ac3c08554b5d90bce74f86cf4546",
            "eca1f9b4b108490ab4f2545a1f98fc67",
            "202bca939e0f4c15998085be62310703",
            "0714fb08361c410fbaa7e31c51180b3c",
            "e5a7ec5f065f49a2ab0b10d5bce64575",
            "1cc3436cb17d46ccaf1e17385bc8c18a",
            "95c3088a819f4e14813c0e6b1c0bf1e0",
            "940c5e3044f34717b81c6e1dc31f9b15",
            "4bc21b1bf53c483e8536f7e5732125fa",
            "b4eb9c592e5c4e019f68f04ccafb0b9a",
            "809dd920e9da46f58c6be2b43decb595",
            "cc611ded01354b398adf3daa62e6617b",
            "f9fc14fd3abd4219a431108858be8f3e",
            "557e8e47e384407497ff5eaf8b9aede5",
            "45b07f6383e84b2b9797fcdb62ce6015",
            "30bd49a1701c4e93809f984d149219a6",
            "04c765ea6b3e4bd0a9c25073e5de8cc0",
            "eb1144f4a6754735baf8699558f7719a",
            "2cc5ef1d7a0440ec9b8c35a27de1e850",
            "ad0f2d21b03a47eb8a2dae063b34bdc5",
            "657588d432d2493fac5261247920ed79",
            "c7f9d74b905f42baa55da682916b7cb8",
            "a6fb7a11e3f74b909e0e414d2de32f4d",
            "818790befbd54c73aa3c7a16cec12e37",
            "cca3fdb8e16241cf87f2c23b30f036ee",
            "393a64bc975544cdb836cce8699b424d",
            "7774eba20e094ae6a6582c86493ad47c",
            "7690c4e32fd84715867767a796e81276",
            "efd3fc9d872b4f97aa4071032e187618",
            "c202b4ad75314fac873c65d030148911",
            "32665beaf02a4c6f985453275066ab63",
            "705a91a2be964f1581760fc59476c828"
          ]
        },
        "outputId": "e43ab797-0dbb-4027-aaf3-d78a29ea5616"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "LOADING MODELS FOR EVALUATION\n",
            "================================================================================\n",
            "BART loaded\n",
            "FLAN-T5 loaded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "693e966125c24f25952bd05d60164a6e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e57fdd2c2ff44eb2be0d5ce97891b3ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a2a81b8e747e434d9fc0b29a14bf5c86"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ca1c03d601b47e0a590acee14a89210"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22fc74972859434db0f4f157b27fc3bb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "T5 zero-shot loaded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "638f70b420144833b9d1a7b50f1a61c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b4bf3d27d0314bee9a4fa7b237e8a29d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa518db0e484109b2f4815da70b2f81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6643421752c946c2901cb3ff71c80fcd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01a47e0fef1147f6842c16c2fa24d7c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "809dd920e9da46f58c6be2b43decb595"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7f9d74b905f42baa55da682916b7cb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM baseline loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 7: GENERATION FUNCTIONS\n",
        "# ==================================================\n",
        "\n",
        "INSTRUCTION = \"\"\"Generate a clinical summary:\n",
        "Symptoms: [patient symptoms]\n",
        "Assessment: [diagnosis/findings]\n",
        "Treatment Plan: [medications, instructions]\"\"\"\n",
        "\n",
        "def generate(model, tokenizer, dialogue, prefix=\"\"):\n",
        "    prompt = f\"{prefix}{INSTRUCTION}\\n\\nDialogue: {dialogue}\\n\\nSummary:\"\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=400, truncation=True).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=150, num_beams=4)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def bart_gen(d): return generate(bart_model, bart_tokenizer, d)\n",
        "def flan_gen(d): return generate(flan_model, flan_tokenizer, d, \"summarize: \")\n",
        "def t5_gen(d): return generate(t5_model, t5_tokenizer, d, \"summarize: \")\n",
        "def llm_gen(d): return generate(llm_model, llm_tokenizer, d)\n",
        "\n",
        "print(\"\\nGeneration functions ready\")\n"
      ],
      "metadata": {
        "id": "TGD6VsHOTe_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae201d8-b579-4dbc-eedb-fd031c0409db"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generation functions ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 8: RAG PIPELINE - COMPLETELY FIXED\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BUILDING RAG PIPELINE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"Embedding model loaded\")\n",
        "\n",
        "# Convert to Python lists (not HuggingFace Dataset)\n",
        "train_dialogues = list(raw_datasets['train']['dialogue_text'])\n",
        "train_summaries = list(raw_datasets['train']['reference_summary'])\n",
        "\n",
        "print(\"Building FAISS index...\")\n",
        "train_embeddings = embed_model.encode(train_dialogues, show_progress_bar=True, batch_size=32, convert_to_numpy=True)\n",
        "\n",
        "rag_index = faiss.IndexFlatL2(train_embeddings.shape[1])\n",
        "rag_index.add(train_embeddings.astype('float32'))\n",
        "print(f\"FAISS index: {rag_index.ntotal} vectors\")\n",
        "\n",
        "def retrieve(dialogue, k=3):\n",
        "    \"\"\"Retrieve k similar examples\"\"\"\n",
        "    query_emb = embed_model.encode([dialogue], convert_to_numpy=True)\n",
        "    distances, indices = rag_index.search(query_emb.astype('float32'), k)\n",
        "\n",
        "    # Convert numpy int64 to Python int\n",
        "    examples = []\n",
        "    for idx in indices[0]:\n",
        "        idx = int(idx)  # CRITICAL FIX\n",
        "        examples.append({\n",
        "            'dialogue': train_dialogues[idx],\n",
        "            'summary': train_summaries[idx]\n",
        "        })\n",
        "    return examples\n",
        "\n",
        "def rag_gen(dialogue, k=3):\n",
        "    \"\"\"Generate with RAG\"\"\"\n",
        "    examples = retrieve(dialogue, k)\n",
        "\n",
        "    # Build context from examples\n",
        "    context = \"\\n\\n\".join([\n",
        "        f\"Example {i+1}:\\nDialogue: {ex['dialogue'][:150]}...\\nSummary: {ex['summary'][:100]}...\"\n",
        "        for i, ex in enumerate(examples)\n",
        "    ])\n",
        "\n",
        "    # Create prompt\n",
        "    prompt = f\"\"\"{INSTRUCTION}\n",
        "\n",
        "Here are some examples:\n",
        "{context}\n",
        "\n",
        "Now summarize this dialogue:\n",
        "Dialogue: {dialogue}\n",
        "\n",
        "Summary:\"\"\"\n",
        "\n",
        "    # Generate with LLM\n",
        "    inputs = llm_tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=450,\n",
        "        truncation=True\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = llm_model.generate(\n",
        "            **inputs,\n",
        "            max_length=150,\n",
        "            num_beams=4,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "    return llm_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "# Test RAG\n",
        "print(\"\\nTesting RAG...\")\n",
        "test_dialogue = raw_datasets['test']['dialogue_text'][0]\n",
        "test_rag = rag_gen(test_dialogue, k=3)\n",
        "print(f\"Sample RAG output: {test_rag[:150]}...\")\n",
        "\n",
        "print(\"\\nRAG pipeline ready\")"
      ],
      "metadata": {
        "id": "UC_pYmavSqQ1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609,
          "referenced_widgets": [
            "80cd37bbbbaf42be8cbf1f509137b549",
            "c581dfa1a8da435ca8decafa37c8935b",
            "de9f4f349ff2442ba20e87e66ff38cd3",
            "25af65f93f5a48f792daa840a46ea3d0",
            "d65935f8a281428da937257e2ac88d33",
            "63140bab16aa4d489eb13458f8465b34",
            "d2fc54f7c73b4302acf92667b2f0812d",
            "9a3c3691519e4795aa2d0b2acce8ea88",
            "e351f22bc4cd474493b1ed112a082d5f",
            "05296a251a3042a8bbc7e15543aa2db4",
            "22960517c79d417b91cdb21436f67b08",
            "f1d475e509b14c82b99539367e16e96c",
            "d673899d88c84b8f8a7674448e711830",
            "d6b3b89d740349979ba047cab40d2404",
            "f8163eee5dbc4fc19390ba0c7fabd05a",
            "30f70567137645c48b94de1b8c2afd30",
            "250101517fed4c728150dcadc4e8c3a6",
            "c7ecc3d7b94e4808adeb09c73a9aabdd",
            "b0ab884a62144588a587cd453a72663d",
            "aba828510d91481ba73beb63d6242bdc",
            "aab03b30e6be41eda8bf043f53e123ac",
            "4ab8b1e444174ed49febb29c5d3dd03f",
            "6af627aa701f432cbceed506813555a8",
            "7cfb4ca8ad1d4a49a3b031a47d6889f7",
            "713dd3278b1c444284040cdf21e091ad",
            "e6b00223723648de8b07f5d8bf279545",
            "5cd4d78b6e8e46a485ebc4ba1843183d",
            "67461e001d884088adec7f10653733cc",
            "a7dc8996aa5241e68eb702fc61c285e5",
            "8eee75266a7b42db832d30699a2edbac",
            "e0d2edc132224db29e48ee520db9763c",
            "3b64b461a8fa4538afcfeb757ee0f35a",
            "a1a94d04794e48148d0fb7a4c31b690a",
            "f6a452f5d2254f7bbccbea71f86e026f",
            "9ddadf9b2e194bf49cb1fd7c369c446e",
            "9b5afa9292934ab987179d3476730aec",
            "246fbc32342f4e7d85915d30760192fb",
            "f6cd5c6d9fb94c59b973eec10d49e887",
            "30be021f16dd4d0a94446a9334ce0a93",
            "e41eb7388130435d8275f4d6cca2ae93",
            "9f7f197609d04df097252c32b7585e99",
            "6c4ab7d72ad945ab9f1690b375e99fcc",
            "60a021ae8eb2448299e7a3bf4fb2490b",
            "08a012a186b849af87f064fc4c21c160",
            "a6a07c074cb84fbcb6d8e19bc4c1f877",
            "7f3dfcf2b66e4701b5f08f8526fa8dd1",
            "36c9b6654bbc4fb18dec041c2227efe5",
            "81c30b1ca3e04880a99627b054399b97",
            "189d0cda3eaf41cb9271740cf421eabf",
            "d48dbd067ae3435eb5303980fdeb2318",
            "567a8fcdb9b142cb9e289cc8cd9eaf34",
            "5863278b9f62457f9e94e005cea5f7cb",
            "9e534b00f14840f6be40a4d2c370f133",
            "f888c9ea2e5d4aac9ff010cbf30d8ca3",
            "6a155180a803480abab801a8347baf06",
            "90ef4219cdf64dac8e5cbef3c16d832d",
            "092e461fc5b24694b5934d57a3828a33",
            "538b27f3af31430dbaed4a4b7f8ad5b8",
            "56e7cabc79ee419aa69e7e7764a667e7",
            "94973bf9f0be4044858df6a8a7b4ea2f",
            "e5e9ecb00e9845e4ae61dd7e6fcc4bac",
            "683ec7064d8f4d65bfd192cc84382eb3",
            "0e746830dcc14daabbe6ae48ec89aef4",
            "8d8d95e447134276827d00c1677c3001",
            "466e832a78be41ec92be18e872b88c70",
            "2da34fd0708d4c56989f360c933bef88",
            "aedc62a4c9dd417db73a695292f9bf04",
            "df454af3cd814fd396393d27468079a9",
            "c96eedfde96a45f582756b540e247cc5",
            "2db718eec33f466194ea82ae2a385e1a",
            "4341ee4689b9476683a12b897d311dc3",
            "66770f724f204c67a8ec39ff7173b7ab",
            "14486a8173094b808789b7c7ec7bae49",
            "5157f5327eb74a4698c1043b4965cfba",
            "e2b6ec01b328411c907fd31afd7f1a1c",
            "8cebf110662d4168bbbd7dcfd35ae8e4",
            "a0d63d79f7104a8c8151881c114e89ea",
            "556a41d97fcd4e7197aacb8c91094d41",
            "32f15bc2d5b0409cb4e0343acce0bb26",
            "132de4bad5db402e8f43d79ec5c1286f",
            "155712ed1e704a47b7c501b99fd72188",
            "9f02238cb5de414c8508ee60fc01e17f",
            "0ab2827e91284cbdb89ca1038ad695ad",
            "ede401ce836b4defbe53638af4ea7114",
            "c6d27c5999c14ade9994ce50fd6d023b",
            "7befbf7cfd5f4325b6fd5a3661153190",
            "4986b24f57e0460383e10cdbfb87de0e",
            "714bdf96e37147a4bd0accc544d1ab3a",
            "63591c09a44d4f5abca0d330c4581902",
            "5842f705a2ef43bd98efd9ee6ba42ff9",
            "b9c3990509074020b1363d6b2e37ced2",
            "f24e41f00fa34405b53e96281b840e58",
            "c28f3285d1e84e8bbb1ee9fb8b219e98",
            "f147c3618102496ab271cb923c667354",
            "8e3efdc39b98471b8f3532922bb4f06a",
            "29634f54104244d8a5d22efeaad543bf",
            "ebed1932b5784f1eb2d2b4d8864b2970",
            "b3ec664d845e4538bcd92710de1a9195",
            "ae063fa656ae40dd8049c006c72964b6",
            "88c31bc67787466dae6f48d8e3c56313",
            "f31bae921bfd4972ba354224e38061c9",
            "3f925d1aa15d4126b48691d4e83d56c0",
            "182209ca2078485aa098c09a36c65d1b",
            "ed62da0714014e2ea1bc8b0e909f4027",
            "4fcf1ab8efc0408891d73177f828a14a",
            "fd47e29ade774973a93531fd4d374d41",
            "b5425f5b71ac49fd9990aaf1da3b000a",
            "3cbaafc9bb2e4864a9af836b1bd54c38",
            "cbe4a7b9551d4ae7b2438330ea0d43a3",
            "a8e305dec80e4913996b8e154056ebf1",
            "805265debfa84a4684ed5dcc8a1ab54f",
            "98f0b33ba82747dca3de43ca850a5d76",
            "cf724b9f6e6b4f80b7050cab616af9c8",
            "13688a315fe643bd8ee889f8a6582f2e",
            "3d618c9c3c2f4dad8269fb1e65d26660",
            "c12ca6a49bc149a1aa86e0d2050efa8e",
            "8a704d23d1964dcbbd18c79c7520eabf",
            "649e23179fd244a998889ffb40119700",
            "c2e9973e65c943eca266420152b1eafc",
            "4f42100923ca41a7b2a99cc054344967",
            "f61d6bcf112641cf8c4b2f2eb523b3f3",
            "1f40c2ece00c48998bf3d5f53b9ff30d",
            "fbf5dcf02fe94b67b1574289a77cee13",
            "2356596d97454902806edd5e25d3130f",
            "889db049b458446faa8e7243fece7d88",
            "733bb5f5ce724818869d3560608ddf82",
            "a5554eff1c284620877a29055aee08a6",
            "c5315afb2a7e4430b1da3fb8a1f53d18",
            "e50570ae57ad48be9ab9f866b51c3641",
            "2d0f552379984bb6918165169f2a9c6c",
            "73eaa9537c90482daeb9f43ca9bd7a26",
            "3cb1ebf6693444c78fc11c5404e70498"
          ]
        },
        "outputId": "982117a5-ba04-4e81-b174-f983277e5722"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "BUILDING RAG PIPELINE\n",
            "================================================================================\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "80cd37bbbbaf42be8cbf1f509137b549"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1d475e509b14c82b99539367e16e96c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6af627aa701f432cbceed506813555a8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6a452f5d2254f7bbccbea71f86e026f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6a07c074cb84fbcb6d8e19bc4c1f877"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90ef4219cdf64dac8e5cbef3c16d832d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aedc62a4c9dd417db73a695292f9bf04"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "556a41d97fcd4e7197aacb8c91094d41"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63591c09a44d4f5abca0d330c4581902"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88c31bc67787466dae6f48d8e3c56313"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "805265debfa84a4684ed5dcc8a1ab54f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding model loaded\n",
            "Building FAISS index...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/33 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f40c2ece00c48998bf3d5f53b9ff30d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index: 1040 vectors\n",
            "\n",
            "Testing RAG...\n",
            "Sample RAG output: Summary: Guest_family took him to emergency because he was complaining of pain in his hernia and lower legs....\n",
            "\n",
            "RAG pipeline ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 9: COMPREHENSIVE EVALUATION\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPREHENSIVE EVALUATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def evaluate_approach(fn, dataset, name, n=60):\n",
        "    print(f\"\\n--- {name} ---\")\n",
        "    preds = []\n",
        "    for idx in tqdm(range(n), desc=name):\n",
        "        try:\n",
        "            preds.append(fn(dataset['dialogue_text'][idx]))\n",
        "        except:\n",
        "            preds.append(\"\")\n",
        "\n",
        "    rouge = rouge_metric.compute(predictions=preds, references=dataset['reference_summary'][:n], use_stemmer=True)\n",
        "    results = {\n",
        "        'rouge1': round(rouge['rouge1'] * 100, 2),\n",
        "        'rouge2': round(rouge['rouge2'] * 100, 2),\n",
        "        'rougeL': round(rouge['rougeL'] * 100, 2),\n",
        "        'predictions': preds\n",
        "    }\n",
        "    print(f\"R1={results['rouge1']}, R2={results['rouge2']}, RL={results['rougeL']}\")\n",
        "    return results\n",
        "\n",
        "all_results = {}\n",
        "all_results['bart_finetuned'] = evaluate_approach(bart_gen, raw_datasets['test'], \"BART Fine-tuned\", 60)\n",
        "all_results['flan_finetuned'] = evaluate_approach(flan_gen, raw_datasets['test'], \"FLAN-T5 Fine-tuned\", 60)\n",
        "all_results['t5_zeroshot'] = evaluate_approach(t5_gen, raw_datasets['test'], \"T5 Zero-shot\", 60)\n",
        "all_results['llm_baseline'] = evaluate_approach(llm_gen, raw_datasets['test'], \"LLM Baseline\", 60)\n",
        "\n",
        "for k in [1, 2, 3, 5]:\n",
        "    all_results[f'rag_k{k}'] = evaluate_approach(lambda d, k=k: rag_gen(d, k), raw_datasets['test'], f\"RAG k={k}\", 60)\n",
        "\n",
        "with open('results/evaluation_results.json', 'w') as f:\n",
        "    json.dump(all_results, f)\n",
        "\n",
        "print(\"\\nMILESTONE: 60 samples evaluated per approach\")\n"
      ],
      "metadata": {
        "id": "oTmCFJc0S1vL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 794,
          "referenced_widgets": [
            "ce8469f759cf49a9a296e788e881a8ad",
            "d170ecf2df1e46968dbb105cd19f9e6f",
            "f0506fdf3d3d45e58e5906806ed3caf6",
            "972c529a6a044ababe14477d274d31ac",
            "12f78e0652c9491f8e3a527ac8275cd2",
            "c041acf8032a4acf8d6a21dc2deb22a6",
            "1273d52facd948d194cce3eac7717ab9",
            "353f3b6c4a1e44518470fa2674234651",
            "ee19d6a68858448b8d4b1db9daa05751",
            "fd4591b40e724ac59834a8078851e222",
            "3079816e914d40c9a40f3ee3fb531d23",
            "6faeaec74b464e15bdfa2a1ecca6fd2e",
            "3dabd28a589140ce9de03126f239f80a",
            "1beb8f83e45943a7be5b0cf04c4b6a31",
            "4904fd4023b14f89b7f8ce809a1c5ab9",
            "4c18eb8721ea4a72a6f67ca2179b0297",
            "7b192bc825ba420c887a7eb73b5f95ed",
            "ded8222791dc4c278f884a103494ff13",
            "316c34915d9c4a41b804e5066de70106",
            "98b0c39783d2493f8703be65d7051803",
            "84d77cf655cf4f8c9bc569e49b2f72b3",
            "ce55e56b5cfb458fa3293ebf364a670f",
            "5ac4ee7b3c8c4e31b0bde451a3711cae",
            "d8ae1f2e696d4e068f1a87d03029aec3",
            "8d5a31853f6c4aad8297ce0e303a01eb",
            "ba5811fca0fd45999ee0e048a764b99d",
            "1a7b5c274ec64ac98ef6bd958b30c920",
            "922def267076414eb32144af2fd287d9",
            "57471b0e5a8f4d87b4d8c551bf66585b",
            "f33d094d72d14919a91856921365c197",
            "21cd77cced854713808dd28247da2c28",
            "d58caed5abd648beaf9bfb762e43612c",
            "c0cea356a4944b24b8927c745a9380bb",
            "2638ceeced3f43d1ab0f035e73428850",
            "c04aa8e52f1546a4839349798db0188c",
            "1629a710e47c4731a8d12a13fda8b5bc",
            "5d832e2d6a6f455b9acd54e59b7580a5",
            "9500264190fa4b4c861e4eb2abe7d52e",
            "c6e8baf07c184c78a89e4c6027311453",
            "444daa8e85c84e07aa9606f77b4bce79",
            "9f636da9fce740dfa322f1ae86d6cb4a",
            "5b28ed4abaee425d91c28a6661fc1cf9",
            "86590bdc3a0046328a1503ac8a96c28e",
            "e927a8bbe91c4b5187027e705a129cbf",
            "fecc305eb9a943fe865ef063400c4938",
            "84d46300aac044fb8117a9615c30e80b",
            "15cf5e1bd54545b5aaf5fcaf591072de",
            "d2afeb68fd4249e486b6862e449503f2",
            "40bafa66e85e4cff937695db24438ac3",
            "8409985aac78481ba039eb909e276e8f",
            "3bf588a08f29491281f2e734e750b538",
            "d21597fd0f714ce0a881390806d05add",
            "b637d0c9e2ca4a84bbf27feb4c1655dc",
            "bb9b45e304244dfe83525f93333c7ed0",
            "9f80c9f480184735a7182cdbd3d02768",
            "0d11555fb4b44f8ba7512b6c1ac79325",
            "8b119b298ba54c21bf54a2c649cc593c",
            "68b1b37aca77403fa141e00e20303a29",
            "4d57281ff5e443eb80485d2418afea0e",
            "bd028b5c6d7e41e38c9782be46afcd42",
            "5462cc8884aa43d38217f66107021043",
            "b34bc52fbe3a4dad983c628100da5da7",
            "a3978ede74e447c089abfb290e6e2a2b",
            "ad1c3bf9bbe14313a74190019d33b181",
            "0b96227233f0458e8f97fa1b5e6ffff5",
            "1487c5bbaa3e491b93e7ac77c1f6fa7c",
            "d0c7ea1167474c47bfaa3c2c7cf293a2",
            "4d496466b1c14b29b3a30a51929afd0d",
            "02764ea61a9247fab44b2c40fc2234f6",
            "59bf56f5ee3b48b9a229351019c3f9c4",
            "b6a0dfea9be14fd0b06ca1da3ecddeb2",
            "26bd121e609b415599716d8dd1185c89",
            "d46d0687ae2347c4844c980f445f22fd",
            "e24fdef6236e4e828405dd076d0a1c7c",
            "bc18f3a47fd44adeb34e415e9a8bcabc",
            "97a2fb322eff4a02a0e9e45ba0e8db62",
            "0d7d20b3e4634513bb2cf3956901478a",
            "d484faab0ad74888b1c55facb32182ff",
            "cc84da8083d64ddea1f2b3ba7b4b1a73",
            "77743e4902e84d3e9af1bd703d757b44",
            "6d81116769154e38b375aafdc6ae9a7b",
            "4d5ffd17f61046a3bed8898244e19a26",
            "194c56833e724e2896167bb3466765b9",
            "87b1ef19e9914ca196a6dbea9ad89a8d",
            "5bc8f04fc6694a1d88f6c14020d6f854",
            "b3014494d33643139bdeac7b5e11b398",
            "5545e9d90d65461f87c040cc565d808c",
            "edc0e2812d1d4f48bd181c2d3a7dbd6e"
          ]
        },
        "outputId": "0882be5c-f394-4f95-afac-505b6e3e4667"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPREHENSIVE EVALUATION\n",
            "================================================================================\n",
            "\n",
            "--- BART Fine-tuned ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "BART Fine-tuned:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce8469f759cf49a9a296e788e881a8ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=53.25, R2=35.33, RL=46.94\n",
            "\n",
            "--- FLAN-T5 Fine-tuned ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FLAN-T5 Fine-tuned:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6faeaec74b464e15bdfa2a1ecca6fd2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=31.66, R2=14.95, RL=28.45\n",
            "\n",
            "--- T5 Zero-shot ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "T5 Zero-shot:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ac4ee7b3c8c4e31b0bde451a3711cae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=23.96, R2=6.56, RL=18.37\n",
            "\n",
            "--- LLM Baseline ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "LLM Baseline:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2638ceeced3f43d1ab0f035e73428850"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=28.14, R2=8.2, RL=21.75\n",
            "\n",
            "--- RAG k=1 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RAG k=1:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fecc305eb9a943fe865ef063400c4938"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=27.26, R2=9.89, RL=21.96\n",
            "\n",
            "--- RAG k=2 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RAG k=2:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d11555fb4b44f8ba7512b6c1ac79325"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=28.99, R2=11.09, RL=23.29\n",
            "\n",
            "--- RAG k=3 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RAG k=3:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0c7ea1167474c47bfaa3c2c7cf293a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=25.58, R2=8.83, RL=20.91\n",
            "\n",
            "--- RAG k=5 ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "RAG k=5:   0%|          | 0/60 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d484faab0ad74888b1c55facb32182ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R1=16.95, R2=6.85, RL=14.91\n",
            "\n",
            "MILESTONE: 60 samples evaluated per approach\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# 10: ABLATION STUDIES\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ABLATION STUDIES\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "ablation = {}\n",
        "\n",
        "# Retrieval impact\n",
        "ablation['retrieval_impact'] = {\n",
        "    'rouge1_delta': all_results['rag_k3']['rouge1'] - all_results['llm_baseline']['rouge1'],\n",
        "    'rouge2_delta': all_results['rag_k3']['rouge2'] - all_results['llm_baseline']['rouge2'],\n",
        "}\n",
        "print(f\"Retrieval impact: R1={ablation['retrieval_impact']['rouge1_delta']:+.2f}\")\n",
        "\n",
        "# Fine-tuning impact\n",
        "ablation['finetuning_impact'] = {\n",
        "    'bart_vs_zeroshot': all_results['bart_finetuned']['rouge1'] - all_results['t5_zeroshot']['rouge1'],\n",
        "}\n",
        "print(f\"Fine-tuning impact: {ablation['finetuning_impact']['bart_vs_zeroshot']:+.2f}\")\n",
        "\n",
        "# K-value sensitivity\n",
        "ablation['k_sensitivity'] = {f'k{k}': all_results[f'rag_k{k}']['rouge1'] for k in [1,2,3,5]}\n",
        "print(f\"K-values: {ablation['k_sensitivity']}\")\n",
        "\n",
        "with open('results/ablation_studies.json', 'w') as f:\n",
        "    json.dump(ablation, f)\n",
        "\n",
        "print(\"\\nMILESTONE: 3 ablation studies\")\n"
      ],
      "metadata": {
        "id": "Ey83RrfiSwYl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83217f1-1826-4a64-8a00-2ff199836f44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ABLATION STUDIES\n",
            "================================================================================\n",
            "Retrieval impact: R1=-2.56\n",
            "Fine-tuning impact: +29.29\n",
            "K-values: {'k1': np.float64(27.26), 'k2': np.float64(28.99), 'k3': np.float64(25.58), 'k5': np.float64(16.95)}\n",
            "\n",
            "MILESTONE: 3 ablation studies\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# CELL 11: EFFICIENCY ANALYSIS\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EFFICIENCY ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def measure_latency(fn, sample_text, runs=5):\n",
        "    times = []\n",
        "    for _ in range(runs):\n",
        "        start = time.time()\n",
        "        _ = fn(sample_text)\n",
        "        times.append(time.time() - start)\n",
        "    return round(np.mean(times), 3)\n",
        "\n",
        "sample_dialogue = raw_datasets['test']['dialogue_text'][0]\n",
        "\n",
        "efficiency = {\n",
        "    \"bart_finetuned_latency\": measure_latency(bart_gen, sample_dialogue),\n",
        "    \"flan_finetuned_latency\": measure_latency(flan_gen, sample_dialogue),\n",
        "    \"t5_zeroshot_latency\": measure_latency(t5_gen, sample_dialogue),\n",
        "    \"llm_baseline_latency\": measure_latency(llm_gen, sample_dialogue),\n",
        "    \"rag_latency_k3\": measure_latency(lambda d: rag_gen(d, 3), sample_dialogue),\n",
        "}\n",
        "\n",
        "eff_df = pd.DataFrame.from_dict(efficiency, orient=\"index\", columns=[\"seconds\"])\n",
        "eff_df.to_csv(\"results/efficiency.csv\")\n",
        "\n",
        "print(\"Efficiency recorded\")\n",
        "display(eff_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "SssogwHxR394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "05548e74-d88a-491c-ebd0-0834c43a7967"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "EFFICIENCY ANALYSIS\n",
            "================================================================================\n",
            "Efficiency recorded\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                        seconds\n",
              "bart_finetuned_latency    0.588\n",
              "flan_finetuned_latency    3.392\n",
              "t5_zeroshot_latency       1.802\n",
              "llm_baseline_latency      1.138\n",
              "rag_latency_k3            1.659"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d77345d8-cbb9-47e4-9a7d-6ce6e5848141\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seconds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>bart_finetuned_latency</th>\n",
              "      <td>0.588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>flan_finetuned_latency</th>\n",
              "      <td>3.392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t5_zeroshot_latency</th>\n",
              "      <td>1.802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llm_baseline_latency</th>\n",
              "      <td>1.138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rag_latency_k3</th>\n",
              "      <td>1.659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d77345d8-cbb9-47e4-9a7d-6ce6e5848141')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d77345d8-cbb9-47e4-9a7d-6ce6e5848141 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d77345d8-cbb9-47e4-9a7d-6ce6e5848141');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b56bee9c-7a9b-41e4-b11f-0eeaea4b2b83\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b56bee9c-7a9b-41e4-b11f-0eeaea4b2b83')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b56bee9c-7a9b-41e4-b11f-0eeaea4b2b83 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3f7d7826-3e6a-4b3b-a850-815b8a39dd89\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('eff_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3f7d7826-3e6a-4b3b-a850-815b8a39dd89 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('eff_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "eff_df",
              "summary": "{\n  \"name\": \"eff_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"seconds\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0519135896070553,\n        \"min\": 0.588,\n        \"max\": 3.392,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.392,\n          1.659,\n          1.802\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# CELL 12: HUMAN EVALUATION (35 SAMPLES)\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"HUMAN EVALUATION SAMPLING\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "human_eval_samples = df_test.sample(35, random_state=SEED)\n",
        "\n",
        "human_eval_output = []\n",
        "\n",
        "for _, row in human_eval_samples.iterrows():\n",
        "    dialogue = row[\"dialogue_text\"]\n",
        "    reference = row[\"reference_summary\"]\n",
        "\n",
        "    entry = {\n",
        "        \"dialogue\": dialogue,\n",
        "        \"reference\": reference,\n",
        "        \"bart_finetuned\": bart_gen(dialogue),\n",
        "        \"flan_finetuned\": flan_gen(dialogue),\n",
        "        \"t5_zeroshot\": t5_gen(dialogue),\n",
        "        \"rag_k3\": rag_gen(dialogue, 3)\n",
        "    }\n",
        "    human_eval_output.append(entry)\n",
        "\n",
        "with open(\"results/human_evaluation_35.json\", \"w\") as f:\n",
        "    json.dump(human_eval_output, f, indent=2)\n",
        "\n",
        "print(\"35-sample human evaluation prepared\")"
      ],
      "metadata": {
        "id": "T0seu080R9Xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe88673-ed24-4d40-bb28-38833a2634d2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "HUMAN EVALUATION SAMPLING\n",
            "================================================================================\n",
            "35-sample human evaluation prepared\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# CELL 13: ERROR TAXONOMY\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ERROR TAXONOMY GENERATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "error_types = [\n",
        "    \"Missing key symptoms\",\n",
        "    \"Incorrect diagnosis inferred\",\n",
        "    \"Fabricated treatment plan\",\n",
        "    \"Overly generic phrasing\",\n",
        "    \"Incorrect merging of speakers\",\n",
        "    \"Over-shortening losing medical details\",\n",
        "    \"Missing medications or dosage\",\n",
        "    \"Wrong temporal ordering\"\n",
        "]\n",
        "\n",
        "taxonomy_results = {}\n",
        "\n",
        "for model_name in [\"bart_finetuned\", \"flan_finetuned\", \"t5_zeroshot\", \"rag_k3\"]:\n",
        "    taxonomy_results[model_name] = {\n",
        "        \"missing_symptoms\": 0,\n",
        "        \"incorrect_diagnosis\": 0,\n",
        "        \"fabrication\": 0,\n",
        "        \"generic\": 0\n",
        "    }\n",
        "\n",
        "    # quick lightweight heuristic checks\n",
        "    for item in human_eval_output:\n",
        "        pred = item[model_name]\n",
        "        ref = item[\"reference\"]\n",
        "\n",
        "        if len(pred) < 40:\n",
        "            taxonomy_results[model_name][\"generic\"] += 1\n",
        "        if \"pain\" in ref and \"pain\" not in pred:\n",
        "            taxonomy_results[model_name][\"missing_symptoms\"] += 1\n",
        "        if (\"diagnosis\" in pred.lower()) is False:\n",
        "            taxonomy_results[model_name][\"incorrect_diagnosis\"] += 1\n",
        "        if \"XYZ\" in pred:\n",
        "            taxonomy_results[model_name][\"fabrication\"] += 1\n",
        "\n",
        "with open(\"results/error_taxonomy.json\", \"w\") as f:\n",
        "    json.dump(taxonomy_results, f, indent=2)\n",
        "\n",
        "print(\"Error taxonomy saved\")"
      ],
      "metadata": {
        "id": "XcPytY9uR-CS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0289263-2bce-4994-f7a5-dda246cdb331"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "ERROR TAXONOMY GENERATION\n",
            "================================================================================\n",
            "Error taxonomy saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================================================\n",
        "# CELL 14: FINAL EXPORT (ALL RESULTS)\n",
        "# ==================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"FINAL EXPORT\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "final_bundle = {\n",
        "    \"finetuned_results\": finetuned_results,\n",
        "    \"all_results\": all_results,\n",
        "    \"efficiency\": efficiency,\n",
        "    \"ablation\": ablation,\n",
        "    \"error_taxonomy\": taxonomy_results,\n",
        "}\n",
        "\n",
        "with open(\"results/final_bundle.json\", \"w\") as f:\n",
        "    json.dump(final_bundle, f, indent=2)\n",
        "\n",
        "print(\"PROJECT COMPLETE!\")"
      ],
      "metadata": {
        "id": "_nqSNjd8fQhE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95690959-3890-4ffa-b9a4-d0218a97c780"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "FINAL EXPORT\n",
            "================================================================================\n",
            "PROJECT COMPLETE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8GDp_0qfVsL6"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}